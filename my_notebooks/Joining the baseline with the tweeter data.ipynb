{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2ba3e4bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import glob\n",
    "import os\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "820e8612",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"../stocks_1m/raw_data_candles/*.csv\" # for the 1 min data\n",
    "path2 = \"../stocks_1d/raw_data_candles/*.csv\" # # for the 1 day data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aae5bd4",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# This block creates a DF for each stock CSV file in the folder (path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9ce3a4c1",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "\n",
    "dfs = []\n",
    "dfs_names = []\n",
    "for file in glob.glob(path):\n",
    "    # extract the file name without the extension\n",
    "    file_name = os.path.splitext(os.path.basename(file))[0]\n",
    "    dfs_names.append(file_name)\n",
    "    # read the CSV file into a dataframe\n",
    "    df = pd.read_csv(file)\n",
    "    \n",
    "    \n",
    "    #preprocess:\n",
    "    df = df.drop(columns=\"symbol\")\n",
    "    df[\"time\"] = pd.to_datetime(df[\"time\"])\n",
    "    df.index = df.pop('time')\n",
    "    \n",
    "    # creat list:\n",
    "    dfs.append(df)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fd1f54e",
   "metadata": {},
   "source": [
    "# This is the step where we can join the tweet data separated by stock"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96502c19",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# This converts the data into the input shape necessary for  the LSTM, and splits X and y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9a713391",
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(29, 360, 5)\n",
      "(29, 360, 1)\n"
     ]
    }
   ],
   "source": [
    "nr_dataframes = len(dfs)\n",
    "nr_rows = 360\n",
    "nr_features = 5\n",
    "\n",
    "# Create an empty array to store the data\n",
    "x_array = np.zeros((nr_dataframes, nr_rows, nr_features))\n",
    "y_array = np.zeros((nr_dataframes, nr_rows))\n",
    "\n",
    "# Loop through the dataframes and slice the last 1000 rows\n",
    "for i, df in enumerate(dfs):\n",
    "    sliced_df_x = df[:-1].tail(nr_rows)\n",
    "    sliced_df_y = df.tail(nr_rows)\n",
    "\n",
    "    # Convert the sliced dataframe to a numpy array\n",
    "    x_df = np.array(sliced_df_x)\n",
    "    \n",
    "\n",
    "    # Add the numpy array to the empty array\n",
    "    x_array[i, :, :] = x_df\n",
    "\n",
    "    # Extract the 'close' column as a numpy array and add it to y_array\n",
    "    close_prices = sliced_df_y['close'].to_numpy()\n",
    "    y_array[i, :] = close_prices\n",
    "    \n",
    "    X = x_array\n",
    "    y = np.expand_dims(y_array.astype(np.float32),axis=-1)\n",
    "\n",
    "# Print the shape of the final arrays\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "184cb05b",
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[8.79900000e+01, 8.79900000e+01, 8.78900000e+01, 8.79658000e+01,\n",
       "         9.86990000e+04],\n",
       "        [8.79500000e+01, 8.79600000e+01, 8.78800000e+01, 8.79200000e+01,\n",
       "         1.09935000e+05],\n",
       "        [8.79250000e+01, 8.80700000e+01, 8.79250000e+01, 8.80415000e+01,\n",
       "         1.08495000e+05],\n",
       "        ...,\n",
       "        [8.59600000e+01, 8.59600000e+01, 8.59600000e+01, 8.59600000e+01,\n",
       "         1.19000000e+02],\n",
       "        [8.59600000e+01, 8.59600000e+01, 8.59600000e+01, 8.59600000e+01,\n",
       "         2.36000000e+02],\n",
       "        [8.60000000e+01, 8.60000000e+01, 8.60000000e+01, 8.60000000e+01,\n",
       "         5.66000000e+02]],\n",
       "\n",
       "       [[2.62477277e+02, 2.62696723e+02, 2.62467302e+02, 2.62547200e+02,\n",
       "         2.12110000e+04],\n",
       "        [2.62587000e+02, 2.62636874e+02, 2.62477277e+02, 2.62507201e+02,\n",
       "         3.10070000e+04],\n",
       "        [2.62507201e+02, 2.62936119e+02, 2.62427403e+02, 2.62886244e+02,\n",
       "         5.98560000e+04],\n",
       "        ...,\n",
       "        [2.57360197e+02, 2.57360197e+02, 2.57350222e+02, 2.57350222e+02,\n",
       "         2.61000000e+03],\n",
       "        [2.57350222e+02, 2.57350222e+02, 2.57350222e+02, 2.57350222e+02,\n",
       "         2.28000000e+02],\n",
       "        [2.57350222e+02, 2.57350222e+02, 2.57350222e+02, 2.57350222e+02,\n",
       "         4.49000000e+02]],\n",
       "\n",
       "       [[3.03735811e+01, 3.04130786e+01, 3.03695326e+01, 3.03883927e+01,\n",
       "         2.17221000e+05],\n",
       "        [3.03883927e+01, 3.03933299e+01, 3.02748374e+01, 3.02782934e+01,\n",
       "         1.43293000e+05],\n",
       "        [3.02748374e+01, 3.03340836e+01, 3.02649630e+01, 3.03276653e+01,\n",
       "         7.62680000e+04],\n",
       "        ...,\n",
       "        [3.00576011e+01, 3.00576011e+01, 3.00576011e+01, 3.00576011e+01,\n",
       "         3.28000000e+02],\n",
       "        [3.00576011e+01, 3.00576011e+01, 3.00477267e+01, 3.00477267e+01,\n",
       "         6.28000000e+02],\n",
       "        [3.00674755e+01, 3.00674755e+01, 3.00674755e+01, 3.00674755e+01,\n",
       "         1.18400000e+03]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[1.06812600e+02, 1.06910000e+02, 1.06780000e+02, 1.06890000e+02,\n",
       "         7.74990000e+04],\n",
       "        [1.06885000e+02, 1.07080000e+02, 1.06885000e+02, 1.07070000e+02,\n",
       "         9.53200000e+04],\n",
       "        [1.07075000e+02, 1.07080000e+02, 1.06850100e+02, 1.06900000e+02,\n",
       "         1.12162000e+05],\n",
       "        ...,\n",
       "        [1.04750000e+02, 1.04780000e+02, 1.04750000e+02, 1.04780000e+02,\n",
       "         1.05800000e+03],\n",
       "        [1.04730000e+02, 1.04730000e+02, 1.04730000e+02, 1.04730000e+02,\n",
       "         5.43000000e+02],\n",
       "        [1.04670000e+02, 1.04670000e+02, 1.04670000e+02, 1.04670000e+02,\n",
       "         7.60000000e+02]],\n",
       "\n",
       "       [[1.70400000e+01, 1.70450000e+01, 1.70200000e+01, 1.70237000e+01,\n",
       "         3.33470000e+04],\n",
       "        [1.70250000e+01, 1.70300000e+01, 1.70200000e+01, 1.70250000e+01,\n",
       "         1.55950000e+04],\n",
       "        [1.70250000e+01, 1.70300000e+01, 1.70200000e+01, 1.70300000e+01,\n",
       "         6.36300000e+03],\n",
       "        ...,\n",
       "        [1.70300000e+01, 1.70300000e+01, 1.70300000e+01, 1.70300000e+01,\n",
       "         1.38360000e+04],\n",
       "        [1.70300000e+01, 1.70300000e+01, 1.70300000e+01, 1.70300000e+01,\n",
       "         3.01100000e+03],\n",
       "        [1.70300000e+01, 1.70300000e+01, 1.70300000e+01, 1.70300000e+01,\n",
       "         2.00000000e+03]],\n",
       "\n",
       "       [[2.15065000e+02, 2.15210000e+02, 2.14959400e+02, 2.15060000e+02,\n",
       "         7.07700000e+04],\n",
       "        [2.15100000e+02, 2.15100000e+02, 2.14811800e+02, 2.14889900e+02,\n",
       "         5.15830000e+04],\n",
       "        [2.14850000e+02, 2.15080000e+02, 2.14680000e+02, 2.15056000e+02,\n",
       "         5.57640000e+04],\n",
       "        ...,\n",
       "        [2.10810000e+02, 2.10810000e+02, 2.10650000e+02, 2.10650000e+02,\n",
       "         5.92000000e+02],\n",
       "        [2.10810000e+02, 2.10810000e+02, 2.10650000e+02, 2.10650000e+02,\n",
       "         4.39000000e+02],\n",
       "        [2.10650000e+02, 2.10650000e+02, 2.10650000e+02, 2.10650000e+02,\n",
       "         3.79000000e+02]]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49bd94fb",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Next step is scalling tha data and feed it to the model (review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "52cd48f0",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler(feature_range=(0, 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8481bbcf",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(units=50, return_sequences=True, input_shape=(n_steps, n_features)))\n",
    "model.add(LSTM(units=50))\n",
    "model.add(Dense(units=1))\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ed01b00a",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_4 (LSTM)               (None, 360, 50)           11200     \n",
      "                                                                 \n",
      " lstm_5 (LSTM)               (None, 50)                20200     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 51        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 31,451\n",
      "Trainable params: 31,451\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2d840bf6",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"/home/armando/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/keras/engine/training.py\", line 1160, in train_function  *\n        return step_function(self, iterator)\n    File \"/home/armando/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/keras/engine/training.py\", line 1146, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/armando/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/keras/engine/training.py\", line 1135, in run_step  **\n        outputs = model.train_step(data)\n    File \"/home/armando/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/keras/engine/training.py\", line 993, in train_step\n        y_pred = self(x, training=True)\n    File \"/home/armando/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/home/armando/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/keras/engine/input_spec.py\", line 295, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"sequential_2\" is incompatible with the layer: expected shape=(None, 360, 5), found shape=(None, 60, 5)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [37], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_X\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_y\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/tmp/__autograph_generated_file4g646tc8.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(step_function), (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m), ag__\u001b[38;5;241m.\u001b[39mld(iterator)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m     17\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/home/armando/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/keras/engine/training.py\", line 1160, in train_function  *\n        return step_function(self, iterator)\n    File \"/home/armando/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/keras/engine/training.py\", line 1146, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/armando/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/keras/engine/training.py\", line 1135, in run_step  **\n        outputs = model.train_step(data)\n    File \"/home/armando/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/keras/engine/training.py\", line 993, in train_step\n        y_pred = self(x, training=True)\n    File \"/home/armando/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/home/armando/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/keras/engine/input_spec.py\", line 295, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"sequential_2\" is incompatible with the layer: expected shape=(None, 360, 5), found shape=(None, 60, 5)\n"
     ]
    }
   ],
   "source": [
    "model.fit(train_X, train_y, epochs=10, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdd90a8a",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for df in df:\n",
    "    df = df.drop(\"symbol\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e368821d",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3e14add",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17df0925",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09f87fa4",
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b84b911",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1a9feca",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def clean_cashtags(st):\n",
    "    letters = re.findall('[A-Za-z]+', st)\n",
    "    return ' '.join(letters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dcfb948",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df = df.dropna(subset=[\"cashtags\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "087e95e7",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df[\"cashtags\"] = df[\"cashtags\"].apply(clean_cashtags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab370eab",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def del_timestamp(st):\n",
    "    return st.replace(\"+00:00\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ed9ca6c",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df[\"date\"] = df[\"date\"].apply(del_timestamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f76f8bf2",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df[\"date\"] = pd.to_datetime(df['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3555e758",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df.index = df.pop('date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc68fbc5",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df[df[\"cashtags\"] == \"MSFT\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de8a6244",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_stocks = pd.read_csv(\"AAPL.csv\")\n",
    "df_stocks.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca4ac94e",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_stocks = df_stocks[['time', 'close']]\n",
    "df_stocks.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f9661ac",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_stocks[\"time\"] = pd.to_datetime(df_stocks[\"time\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a971f2e2",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_stocks.index = df_stocks.pop(\"time\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7715ce7",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_stocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51d741a8",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "scaller = MinMaxScaler()\n",
    "\n",
    "df_stocks[\"close_scalled\"] = scaller.fit_transform(df_stocks[[\"close\"]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58455125",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_stocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "584df763",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "883a1d97",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "merged_df = pd.merge(df, df_stocks, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00aa4539",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34485fb9",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "merged_short = merged_df[['tweet', 'username', 'likeCount', 'replyCount',\n",
    "       'retweetCount', 'sentiment', 'close']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ae1db8d",
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "merged_short"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d7a885e",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_stocks"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
