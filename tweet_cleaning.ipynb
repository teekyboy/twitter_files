{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import re\n",
    "import pickle\n",
    "import emoji\n",
    "import preprocessor\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('raw_data/tweets.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data.drop(columns=['media', 'inReplyToUser', 'mentionedUsers', 'lang', 'source', 'location'])\n",
    "df.rename(columns={'rawContent': 'tweet'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_datetime(df):\n",
    "    df['date'] = pd.to_datetime(df['date'], format='%Y-%m-%d %H:%M:%S')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_emojis(string):\n",
    "    text = emoji.demojize(string)\n",
    "    text = text.replace(\":\", \"\").replace(\"_\", \" \")\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_tweet(tweet):\n",
    "    \n",
    "    # Remove url\n",
    "    tweet = re.sub(r'https?:\\/\\/\\S+', '', tweet)\n",
    "    tweet = re.sub(r'http?:\\/\\/\\S+', '', tweet)\n",
    "    \n",
    "    # Remove \\n\n",
    "    tweet = re.sub(r'\\n', '', tweet)\n",
    "    \n",
    "    # Remove @\n",
    "    tweet = re.sub(r'@[A-Za-z0-9]+', '', tweet)\n",
    "    \n",
    "    # Remove #\n",
    "    tweet = re.sub(r'#', '', tweet)\n",
    "    \n",
    "    # Remove RT\n",
    "    tweet = re.sub(r'RT[\\s]+', '', tweet)\n",
    "    \n",
    "    # Convert to lower case\n",
    "    tweet = tweet.lower()\n",
    "    \n",
    "    # Remove \"#&'()*/:;@[\\]^`{|}~\"\n",
    "    tweet = re.sub(r'[#&\\'\\(\\)\\*\\+\\/:;@\\[\\]\\^`{|}~]', '', tweet)\n",
    "    \n",
    "    # Remove double space\n",
    "    tweet = re.sub(r'\\s\\s+', ' ', tweet)\n",
    "    \n",
    "    return tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_max_normalization(df):\n",
    "    df = df.copy()\n",
    "    \n",
    "    num_cols = df.select_dtypes(include=['float64', 'int64']).columns.tolist()\n",
    "    scaler = MinMaxScaler()\n",
    "    df[num_cols] = scaler.fit_transform(df[num_cols])\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = convert_to_datetime(df)\n",
    "df['tweet'] = df['tweet'].apply(clean_tweet)\n",
    "df['tweet'] = df['tweet'].apply(convert_emojis)\n",
    "df = min_max_normalization(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "list1 = ['AAPL', 'Apple Inc.', 'Appl', 'AMC', 'AMC Entertainment Holdings Inc.', 'AAMC', 'AC', 'AMZN', 'Amazon.com Inc.', 'Amazn', 'AMD', 'Advanced Micro Devices Inc.', 'AMED', 'BB', 'BlackBerry Ltd.', 'Blacberry', 'BBBY', 'Bed Bath & Beyond Inc.', 'Bedbathbeyond', 'BTC', 'Bitcoin', 'bit coin', 'BYND', 'Beyond Meat Inc.', 'Bynd', 'CLNE', 'Clean Energy Fuels Corp.', 'Clnenergy', 'CMG', 'Chipotle Mexican Grill Inc.', 'Chipotle', 'COST', 'Costco Wholesale Corp.', 'Coscto', 'CRSR', 'Corsair Gaming Inc.', 'Corsair', 'DIS', 'Walt Disney Co.', 'Disney', 'DOGE', 'Dogecoin', 'Doge coin', 'ET', 'Energy Transfer LP', 'Energy Transfer', 'F', 'Ford Motor Co.', 'Ford', 'FB', 'Facebook Inc.', 'Fb', 'GME', 'GameStop Corp.', 'Gamestop', 'GOOG', 'Alphabet Inc.', 'Google', 'HD', 'Home Depot Inc.', 'Home Depo', 'INTC', 'Intel Corp.', 'Intell', 'JNJ', 'Johnson & Johnson', 'Johnsohn', 'KO', 'Coca-Cola Co.', 'Coca Cola', 'LULU', 'Lululemon Athletica Inc.', 'Lululemn', 'MCD', \"McDonald's Corp.\", \"McDonalds\", 'MGM', 'MGM Resorts International', 'Mgmresorts', 'MSFT', 'Microsoft Corp.', 'Micrsoft', 'MU', 'Micron Technology Inc.', 'Micron', 'NIO', 'NIO Inc.', 'Nio', 'NVDA', 'NVIDIA Corp.', 'Nivida', 'PFE', 'Pfizer Inc.', 'Pifzer', 'PINS', 'Pinterest Inc.', 'Pintrst', 'PLTR', 'Palantir Technologies Inc.', 'Palintir', 'QQQ', 'Invesco QQQ Trust', 'InvescoQQQ', 'RBLX', 'Roblox Corp.', 'Robloks', 'RIOT', 'Riot Blockchain Inc.', 'Riott', 'ROKU', 'Roku Inc.', 'Rokue', 'SNDL', 'Sundial Growers Inc.', 'Sundail', 'SPCE', 'Virgin Galactic Holdings Inc.', 'Spacex', 'SQ', 'Square Inc.', 'Squar', 'T', 'AT&T Inc.', 'Att', 'TSLA', 'Tesla Inc.', 'Teslla', 'TWTR', 'Twitter Inc.', 'Twiter', 'UBER', 'Uber Technologies Inc.', 'Ube', 'UPST', 'Upstart Holdings Inc.', 'Upstartholdings', 'V', 'Visa Inc.', 'Visa', 'WMT', 'Walmart Inc.', 'Walmrt', 'XOM', 'Exxon Mobil Corp.', 'Exxonmobil']\n",
    "list2 = ['AAL', 'American Airlines Group Inc.', 'Americanairlines',\n",
    "        'ABNB', 'Airbnb Inc.', 'AirBnB',\n",
    "        'ACB', 'Aurora Cannabis Inc.', 'Auroracannabis',\n",
    "        'AMRN', 'Amarin Corp. plc', 'Amerin',\n",
    "        'ARKK', 'ARK Innovation ETF', 'ARKinovation',\n",
    "        'BABA', 'Alibaba Group Holding Ltd.', 'Alibaba',\n",
    "        'BA', 'Boeing Co.', 'Boing',\n",
    "        'BAC', 'Bank of America Corp.', 'Bankofamerica',\n",
    "        'BIDU', 'Baidu Inc.', 'Bido',\n",
    "        'BILI', 'Bilibili Inc.', 'Billibili',\n",
    "        'BLNK', 'Blink Charging Co.', 'Blinkcharg',\n",
    "        'BMY', 'Bristol Myers Squibb Co.', 'Bristolmyers',\n",
    "        'BRK.A', 'Berkshire Hathaway Inc.', 'Berkshira',\n",
    "        'CCL', 'Carnival Corp.', 'Carnival',\n",
    "        'CGC', 'Canopy Growth Corp.', 'Canopygrowth',\n",
    "        'CHWY', 'Chewy Inc.', 'Chewycom',\n",
    "        'CSCO', 'Cisco Systems Inc.', 'Cicsco',\n",
    "        'CVS', 'CVS Health Corp.', 'Cvshealth',\n",
    "        'DAL', 'Delta Air Lines Inc.', 'Deltaairlines',\n",
    "        'DDOG', 'Datadog Inc.', 'DataDog',\n",
    "        'DISCA', 'Discovery Inc. - Class A', 'Discovera',\n",
    "        'DKNG', 'DraftKings Inc.', 'DraftKings',\n",
    "        'ENPH', 'Enphase Energy Inc.', 'Enphase',\n",
    "        'EQT', 'EQT Corp.', 'Eqtcorporation',\n",
    "        'FCEL', 'FuelCell Energy Inc.', 'Fuelcell',\n",
    "        'FSLY', 'Fastly Inc.', 'Fastly',\n",
    "        'GE', 'General Electric Co.', 'GeneralElectric',\n",
    "        'GM', 'General Motors Co.', 'GeneralMotors',\n",
    "        'GOLD', 'Barrick Gold Corp.', 'Goldmining',\n",
    "        'GPRO', 'GoPro Inc.', 'Gopro',\n",
    "        'GRWG', 'GrowGeneration Corp.', 'Growgen',\n",
    "        'HPE', 'Hewlett Packard Enterprise Co.', 'Hewlettpackard',\n",
    "        'IBB', 'iShares NASDAQ Biotechnology ETF', 'iSharesNasdaqBiotechnology',\n",
    "        'IBKR', 'Interactive Brokers Group Inc.', 'InterectiveBrokers',\n",
    "        'INO', 'Inovio Pharmaceuticals Inc.', 'Inovio',\n",
    "        'JD', 'JD.com Inc.', 'JD',\n",
    "        'JMIA', 'Jumia Technologies AG', 'Jumia',\n",
    "        'JPM', 'JPMorgan Chase & Co.', 'JPmorgan',\n",
    "        'KHC', 'Kraft Heinz Co.', 'KraftHeinz',\n",
    "        'LIT', 'Global X Lithium & Battery Tech ETF', 'GlobalXlithium',\n",
    "        'MARA', 'Marathon Digital Holdings Inc.', 'MarathonDigital',\n",
    "        'MRNA', 'Moderna Inc.', 'Modernna',\n",
    "        'NCLH', 'Norwegian Cruise Line Holdings Ltd.', 'Norwegiancruiseline',\n",
    "        'NET', 'Cloudflare Inc.', 'CloudFlare',\n",
    "        'NFLX', 'Netflix Inc.', 'Netlfix',\n",
    "        'NKE', 'Nike Inc.', 'Nike', 'NKLA', 'Nikola Corp.', 'Nicola', 'NOK', 'Nokia Corp.', 'Noka', 'O', 'Realty Income Corp.', 'Realtyincome', 'OGI', 'OrganiGram Holdings Inc.', 'Organigram', 'OTRK', 'Ontrak Inc.', 'OnTrack', 'PDD', 'Pinduoduo Inc.', 'Pinduoduo', 'PENN', 'Penn National Gaming Inc.', 'PennNational']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords = []\n",
    "\n",
    "for word in list1:\n",
    "    word = clean_tweet(word)\n",
    "    word = word.replace('inc.', '').replace('ltd.', '').replace('co.', '').replace('corp.', '').replace('.com', '')\n",
    "    keywords.append(word)\n",
    "\n",
    "for word in list2:\n",
    "    word = clean_tweet(word)\n",
    "    word = word.replace('inc.', '').replace('ltd.', '').replace('co.', '').replace('corp.', '').replace('.com', '')\n",
    "    keywords.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "top50 = pd.read_csv('raw_data/top50.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "cashtags = top50['cashtags'].tolist()\n",
    "hashtags = top50['hashtags'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cashtag in cashtags:\n",
    "    cashtag = clean_tweet(cashtag)\n",
    "    cashtag = re.sub(r'[^\\w\\s]', '', cashtag)\n",
    "    cashtag = cashtag.replace(' ', '')\n",
    "    \n",
    "    if cashtag not in keywords:\n",
    "        keywords.append(cashtag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "for hashtag in hashtags:\n",
    "    hashtag = clean_tweet(hashtag)\n",
    "    hashtag = re.sub(r'[^\\w\\s]', '', hashtag)\n",
    "    hashtag = hashtag.replace(' ', '')\n",
    "    \n",
    "    if hashtag not in keywords:\n",
    "        keywords.append(hashtag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "for keyword in keywords:\n",
    "    if len(keyword) < 2:\n",
    "        keywords.remove(keyword)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered = df[df['tweet'].str.contains(keyword).any() | df['cashtags'].notnull() | df['hashtags'].notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>date</th>\n",
       "      <th>tweet</th>\n",
       "      <th>username</th>\n",
       "      <th>likeCount</th>\n",
       "      <th>replyCount</th>\n",
       "      <th>retweetCount</th>\n",
       "      <th>quoteCount</th>\n",
       "      <th>cashtags</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>viewCount</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>https://twitter.com/unusual_whales/status/1608...</td>\n",
       "      <td>2022-12-30 20:25:41+00:00</td>\n",
       "      <td>$spys intraday flow overview right now link li...</td>\n",
       "      <td>unusual_whales</td>\n",
       "      <td>0.000386</td>\n",
       "      <td>0.000479</td>\n",
       "      <td>0.000391</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>['SPY']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.006192</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>https://twitter.com/unusual_whales/status/1608...</td>\n",
       "      <td>2022-12-30 20:00:21+00:00</td>\n",
       "      <td>covid-19 issues in china are still hampering m...</td>\n",
       "      <td>unusual_whales</td>\n",
       "      <td>0.000874</td>\n",
       "      <td>0.001436</td>\n",
       "      <td>0.000313</td>\n",
       "      <td>0.000246</td>\n",
       "      <td>['AAPL']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.005284</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>https://twitter.com/unusual_whales/status/1608...</td>\n",
       "      <td>2022-12-30 19:53:56+00:00</td>\n",
       "      <td>warren buffett of $brk.b has surpassed jeff be...</td>\n",
       "      <td>unusual_whales</td>\n",
       "      <td>0.002999</td>\n",
       "      <td>0.003230</td>\n",
       "      <td>0.001055</td>\n",
       "      <td>0.000185</td>\n",
       "      <td>['BRK.B', 'AMZN']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.009775</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>https://twitter.com/unusual_whales/status/1608...</td>\n",
       "      <td>2022-12-30 19:51:16+00:00</td>\n",
       "      <td>here are all the current opening flow alerts 1...</td>\n",
       "      <td>unusual_whales</td>\n",
       "      <td>0.000185</td>\n",
       "      <td>0.000479</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>['SNOW', 'PANW', 'SI', 'JD']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.005625</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>https://twitter.com/unusual_whales/status/1608...</td>\n",
       "      <td>2022-12-30 19:30:59+00:00</td>\n",
       "      <td>price action for $tsla today for full charting...</td>\n",
       "      <td>unusual_whales</td>\n",
       "      <td>0.000277</td>\n",
       "      <td>0.001316</td>\n",
       "      <td>0.000352</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>['TSLA']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.006668</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20394</th>\n",
       "      <td>https://twitter.com/unusual_whales/status/1511...</td>\n",
       "      <td>2022-04-06 11:15:00+00:00</td>\n",
       "      <td>$gme flow- putcall ratio 0.577, call premium 3...</td>\n",
       "      <td>unusual_whales</td>\n",
       "      <td>0.000336</td>\n",
       "      <td>0.000598</td>\n",
       "      <td>0.000195</td>\n",
       "      <td>0.000062</td>\n",
       "      <td>['GME']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20395</th>\n",
       "      <td>https://twitter.com/unusual_whales/status/1510...</td>\n",
       "      <td>2022-04-04 14:58:06+00:00</td>\n",
       "      <td>let’s look at politicians and $twtr.no one bou...</td>\n",
       "      <td>unusual_whales</td>\n",
       "      <td>0.001008</td>\n",
       "      <td>0.000957</td>\n",
       "      <td>0.000195</td>\n",
       "      <td>0.000123</td>\n",
       "      <td>['TWTR']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20396</th>\n",
       "      <td>https://twitter.com/unusual_whales/status/1509...</td>\n",
       "      <td>2022-04-01 15:05:46+00:00</td>\n",
       "      <td>$qqq 2022-04-22 c $396underlying $361.51, % di...</td>\n",
       "      <td>unusual_whales</td>\n",
       "      <td>0.000193</td>\n",
       "      <td>0.000120</td>\n",
       "      <td>0.000078</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>['QQQ']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20398</th>\n",
       "      <td>https://twitter.com/unusual_whales/status/1509...</td>\n",
       "      <td>2022-03-31 14:30:36+00:00</td>\n",
       "      <td>$spy 2022-04-29 p $395underlying $457.12, % di...</td>\n",
       "      <td>unusual_whales</td>\n",
       "      <td>0.000160</td>\n",
       "      <td>0.000479</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>['SPY']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20400</th>\n",
       "      <td>https://twitter.com/unusual_whales/status/1507...</td>\n",
       "      <td>2022-03-25 12:57:00+00:00</td>\n",
       "      <td>$bbby flow- putcall ratio 0.274, call premium ...</td>\n",
       "      <td>unusual_whales</td>\n",
       "      <td>0.000445</td>\n",
       "      <td>0.000239</td>\n",
       "      <td>0.000234</td>\n",
       "      <td>0.000062</td>\n",
       "      <td>['BBBY']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8058 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     url  \\\n",
       "11     https://twitter.com/unusual_whales/status/1608...   \n",
       "13     https://twitter.com/unusual_whales/status/1608...   \n",
       "15     https://twitter.com/unusual_whales/status/1608...   \n",
       "16     https://twitter.com/unusual_whales/status/1608...   \n",
       "18     https://twitter.com/unusual_whales/status/1608...   \n",
       "...                                                  ...   \n",
       "20394  https://twitter.com/unusual_whales/status/1511...   \n",
       "20395  https://twitter.com/unusual_whales/status/1510...   \n",
       "20396  https://twitter.com/unusual_whales/status/1509...   \n",
       "20398  https://twitter.com/unusual_whales/status/1509...   \n",
       "20400  https://twitter.com/unusual_whales/status/1507...   \n",
       "\n",
       "                           date  \\\n",
       "11    2022-12-30 20:25:41+00:00   \n",
       "13    2022-12-30 20:00:21+00:00   \n",
       "15    2022-12-30 19:53:56+00:00   \n",
       "16    2022-12-30 19:51:16+00:00   \n",
       "18    2022-12-30 19:30:59+00:00   \n",
       "...                         ...   \n",
       "20394 2022-04-06 11:15:00+00:00   \n",
       "20395 2022-04-04 14:58:06+00:00   \n",
       "20396 2022-04-01 15:05:46+00:00   \n",
       "20398 2022-03-31 14:30:36+00:00   \n",
       "20400 2022-03-25 12:57:00+00:00   \n",
       "\n",
       "                                                   tweet        username  \\\n",
       "11     $spys intraday flow overview right now link li...  unusual_whales   \n",
       "13     covid-19 issues in china are still hampering m...  unusual_whales   \n",
       "15     warren buffett of $brk.b has surpassed jeff be...  unusual_whales   \n",
       "16     here are all the current opening flow alerts 1...  unusual_whales   \n",
       "18     price action for $tsla today for full charting...  unusual_whales   \n",
       "...                                                  ...             ...   \n",
       "20394  $gme flow- putcall ratio 0.577, call premium 3...  unusual_whales   \n",
       "20395  let’s look at politicians and $twtr.no one bou...  unusual_whales   \n",
       "20396  $qqq 2022-04-22 c $396underlying $361.51, % di...  unusual_whales   \n",
       "20398  $spy 2022-04-29 p $395underlying $457.12, % di...  unusual_whales   \n",
       "20400  $bbby flow- putcall ratio 0.274, call premium ...  unusual_whales   \n",
       "\n",
       "       likeCount  replyCount  retweetCount  quoteCount  \\\n",
       "11      0.000386    0.000479      0.000391    0.000000   \n",
       "13      0.000874    0.001436      0.000313    0.000246   \n",
       "15      0.002999    0.003230      0.001055    0.000185   \n",
       "16      0.000185    0.000479      0.000000    0.000000   \n",
       "18      0.000277    0.001316      0.000352    0.000000   \n",
       "...          ...         ...           ...         ...   \n",
       "20394   0.000336    0.000598      0.000195    0.000062   \n",
       "20395   0.001008    0.000957      0.000195    0.000123   \n",
       "20396   0.000193    0.000120      0.000078    0.000000   \n",
       "20398   0.000160    0.000479      0.000039    0.000000   \n",
       "20400   0.000445    0.000239      0.000234    0.000062   \n",
       "\n",
       "                           cashtags hashtags  viewCount sentiment  \n",
       "11                          ['SPY']      NaN   0.006192   Neutral  \n",
       "13                         ['AAPL']      NaN   0.005284   Neutral  \n",
       "15                ['BRK.B', 'AMZN']      NaN   0.009775   Neutral  \n",
       "16     ['SNOW', 'PANW', 'SI', 'JD']      NaN   0.005625   Neutral  \n",
       "18                         ['TSLA']      NaN   0.006668   Neutral  \n",
       "...                             ...      ...        ...       ...  \n",
       "20394                       ['GME']      NaN        NaN   Neutral  \n",
       "20395                      ['TWTR']      NaN        NaN   Neutral  \n",
       "20396                       ['QQQ']      NaN        NaN   Neutral  \n",
       "20398                       ['SPY']      NaN        NaN   Neutral  \n",
       "20400                      ['BBBY']      NaN        NaN   Neutral  \n",
       "\n",
       "[8058 rows x 12 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment_analysis(df):\n",
    "    \n",
    "    from transformers import BertTokenizer, BertForSequenceClassification, pipeline\n",
    "\n",
    "    finbert = BertForSequenceClassification.from_pretrained('yiyanghkust/finbert-tone',num_labels=3)\n",
    "    tokenizer = BertTokenizer.from_pretrained('yiyanghkust/finbert-tone')\n",
    "    nlp = pipeline(\"text-classification\", model=finbert, tokenizer=tokenizer)\n",
    "    \n",
    "    for i in range(len(df)):\n",
    "        results = nlp(df.iloc[i]['tweet'])\n",
    "        df['sentiment'] = results[0]['label']\n",
    "    \n",
    "    return df\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading (…)lve/main/config.json: 100%|██████████| 533/533 [00:00<00:00, 96.4kB/s]\n",
      "Downloading (…)\"pytorch_model.bin\";: 100%|██████████| 439M/439M [00:29<00:00, 15.0MB/s] \n",
      "Downloading (…)solve/main/vocab.txt: 100%|██████████| 226k/226k [00:00<00:00, 486kB/s]\n",
      "/tmp/ipykernel_5166/3005844282.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['sentiment'] = results[0]['label']\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[62], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m sentiment_analysis(df_filtered)\n",
      "Cell \u001b[0;32mIn[61], line 10\u001b[0m, in \u001b[0;36msentiment_analysis\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m      7\u001b[0m nlp \u001b[39m=\u001b[39m pipeline(\u001b[39m\"\u001b[39m\u001b[39mtext-classification\u001b[39m\u001b[39m\"\u001b[39m, model\u001b[39m=\u001b[39mfinbert, tokenizer\u001b[39m=\u001b[39mtokenizer)\n\u001b[1;32m      9\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(df)):\n\u001b[0;32m---> 10\u001b[0m     results \u001b[39m=\u001b[39m nlp(df\u001b[39m.\u001b[39;49miloc[i][\u001b[39m'\u001b[39;49m\u001b[39mtweet\u001b[39;49m\u001b[39m'\u001b[39;49m])\n\u001b[1;32m     11\u001b[0m     df[\u001b[39m'\u001b[39m\u001b[39msentiment\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m results[\u001b[39m0\u001b[39m][\u001b[39m'\u001b[39m\u001b[39mlabel\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m     13\u001b[0m \u001b[39mreturn\u001b[39;00m df\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/twitter-env/lib/python3.10/site-packages/transformers/pipelines/text_classification.py:155\u001b[0m, in \u001b[0;36mTextClassificationPipeline.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    122\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[39m    Classify the text(s) given as inputs.\u001b[39;00m\n\u001b[1;32m    124\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[39m        If `top_k` is used, one such dictionary is returned per label.\u001b[39;00m\n\u001b[1;32m    154\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 155\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    156\u001b[0m     \u001b[39m# TODO try and retrieve it in a nicer way from _sanitize_parameters.\u001b[39;00m\n\u001b[1;32m    157\u001b[0m     _legacy \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mtop_k\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m kwargs\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/twitter-env/lib/python3.10/site-packages/transformers/pipelines/base.py:1084\u001b[0m, in \u001b[0;36mPipeline.__call__\u001b[0;34m(self, inputs, num_workers, batch_size, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1076\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mnext\u001b[39m(\n\u001b[1;32m   1077\u001b[0m         \u001b[39miter\u001b[39m(\n\u001b[1;32m   1078\u001b[0m             \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_iterator(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1081\u001b[0m         )\n\u001b[1;32m   1082\u001b[0m     )\n\u001b[1;32m   1083\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1084\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrun_single(inputs, preprocess_params, forward_params, postprocess_params)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/twitter-env/lib/python3.10/site-packages/transformers/pipelines/base.py:1091\u001b[0m, in \u001b[0;36mPipeline.run_single\u001b[0;34m(self, inputs, preprocess_params, forward_params, postprocess_params)\u001b[0m\n\u001b[1;32m   1089\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrun_single\u001b[39m(\u001b[39mself\u001b[39m, inputs, preprocess_params, forward_params, postprocess_params):\n\u001b[1;32m   1090\u001b[0m     model_inputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpreprocess(inputs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mpreprocess_params)\n\u001b[0;32m-> 1091\u001b[0m     model_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mforward(model_inputs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mforward_params)\n\u001b[1;32m   1092\u001b[0m     outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpostprocess(model_outputs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mpostprocess_params)\n\u001b[1;32m   1093\u001b[0m     \u001b[39mreturn\u001b[39;00m outputs\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/twitter-env/lib/python3.10/site-packages/transformers/pipelines/base.py:992\u001b[0m, in \u001b[0;36mPipeline.forward\u001b[0;34m(self, model_inputs, **forward_params)\u001b[0m\n\u001b[1;32m    990\u001b[0m     \u001b[39mwith\u001b[39;00m inference_context():\n\u001b[1;32m    991\u001b[0m         model_inputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_ensure_tensor_on_device(model_inputs, device\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice)\n\u001b[0;32m--> 992\u001b[0m         model_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_forward(model_inputs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mforward_params)\n\u001b[1;32m    993\u001b[0m         model_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_ensure_tensor_on_device(model_outputs, device\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mdevice(\u001b[39m\"\u001b[39m\u001b[39mcpu\u001b[39m\u001b[39m\"\u001b[39m))\n\u001b[1;32m    994\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/twitter-env/lib/python3.10/site-packages/transformers/pipelines/text_classification.py:182\u001b[0m, in \u001b[0;36mTextClassificationPipeline._forward\u001b[0;34m(self, model_inputs)\u001b[0m\n\u001b[1;32m    181\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_forward\u001b[39m(\u001b[39mself\u001b[39m, model_inputs):\n\u001b[0;32m--> 182\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mmodel_inputs)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/twitter-env/lib/python3.10/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/twitter-env/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py:1563\u001b[0m, in \u001b[0;36mBertForSequenceClassification.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1555\u001b[0m \u001b[39m\u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1556\u001b[0m \u001b[39mlabels (`torch.LongTensor` of shape `(batch_size,)`, *optional*):\u001b[39;00m\n\u001b[1;32m   1557\u001b[0m \u001b[39m    Labels for computing the sequence classification/regression loss. Indices should be in `[0, ...,\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[39m    config.num_labels - 1]`. If `config.num_labels == 1` a regression loss is computed (Mean-Square loss), If\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[39m    `config.num_labels > 1` a classification loss is computed (Cross-Entropy).\u001b[39;00m\n\u001b[1;32m   1560\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1561\u001b[0m return_dict \u001b[39m=\u001b[39m return_dict \u001b[39mif\u001b[39;00m return_dict \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39muse_return_dict\n\u001b[0;32m-> 1563\u001b[0m outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbert(\n\u001b[1;32m   1564\u001b[0m     input_ids,\n\u001b[1;32m   1565\u001b[0m     attention_mask\u001b[39m=\u001b[39;49mattention_mask,\n\u001b[1;32m   1566\u001b[0m     token_type_ids\u001b[39m=\u001b[39;49mtoken_type_ids,\n\u001b[1;32m   1567\u001b[0m     position_ids\u001b[39m=\u001b[39;49mposition_ids,\n\u001b[1;32m   1568\u001b[0m     head_mask\u001b[39m=\u001b[39;49mhead_mask,\n\u001b[1;32m   1569\u001b[0m     inputs_embeds\u001b[39m=\u001b[39;49minputs_embeds,\n\u001b[1;32m   1570\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m   1571\u001b[0m     output_hidden_states\u001b[39m=\u001b[39;49moutput_hidden_states,\n\u001b[1;32m   1572\u001b[0m     return_dict\u001b[39m=\u001b[39;49mreturn_dict,\n\u001b[1;32m   1573\u001b[0m )\n\u001b[1;32m   1575\u001b[0m pooled_output \u001b[39m=\u001b[39m outputs[\u001b[39m1\u001b[39m]\n\u001b[1;32m   1577\u001b[0m pooled_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout(pooled_output)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/twitter-env/lib/python3.10/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/twitter-env/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py:1019\u001b[0m, in \u001b[0;36mBertModel.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1010\u001b[0m head_mask \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_head_mask(head_mask, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mnum_hidden_layers)\n\u001b[1;32m   1012\u001b[0m embedding_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membeddings(\n\u001b[1;32m   1013\u001b[0m     input_ids\u001b[39m=\u001b[39minput_ids,\n\u001b[1;32m   1014\u001b[0m     position_ids\u001b[39m=\u001b[39mposition_ids,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1017\u001b[0m     past_key_values_length\u001b[39m=\u001b[39mpast_key_values_length,\n\u001b[1;32m   1018\u001b[0m )\n\u001b[0;32m-> 1019\u001b[0m encoder_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mencoder(\n\u001b[1;32m   1020\u001b[0m     embedding_output,\n\u001b[1;32m   1021\u001b[0m     attention_mask\u001b[39m=\u001b[39;49mextended_attention_mask,\n\u001b[1;32m   1022\u001b[0m     head_mask\u001b[39m=\u001b[39;49mhead_mask,\n\u001b[1;32m   1023\u001b[0m     encoder_hidden_states\u001b[39m=\u001b[39;49mencoder_hidden_states,\n\u001b[1;32m   1024\u001b[0m     encoder_attention_mask\u001b[39m=\u001b[39;49mencoder_extended_attention_mask,\n\u001b[1;32m   1025\u001b[0m     past_key_values\u001b[39m=\u001b[39;49mpast_key_values,\n\u001b[1;32m   1026\u001b[0m     use_cache\u001b[39m=\u001b[39;49muse_cache,\n\u001b[1;32m   1027\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m   1028\u001b[0m     output_hidden_states\u001b[39m=\u001b[39;49moutput_hidden_states,\n\u001b[1;32m   1029\u001b[0m     return_dict\u001b[39m=\u001b[39;49mreturn_dict,\n\u001b[1;32m   1030\u001b[0m )\n\u001b[1;32m   1031\u001b[0m sequence_output \u001b[39m=\u001b[39m encoder_outputs[\u001b[39m0\u001b[39m]\n\u001b[1;32m   1032\u001b[0m pooled_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpooler(sequence_output) \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpooler \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/twitter-env/lib/python3.10/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/twitter-env/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py:609\u001b[0m, in \u001b[0;36mBertEncoder.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    600\u001b[0m     layer_outputs \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39mcheckpoint\u001b[39m.\u001b[39mcheckpoint(\n\u001b[1;32m    601\u001b[0m         create_custom_forward(layer_module),\n\u001b[1;32m    602\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    606\u001b[0m         encoder_attention_mask,\n\u001b[1;32m    607\u001b[0m     )\n\u001b[1;32m    608\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 609\u001b[0m     layer_outputs \u001b[39m=\u001b[39m layer_module(\n\u001b[1;32m    610\u001b[0m         hidden_states,\n\u001b[1;32m    611\u001b[0m         attention_mask,\n\u001b[1;32m    612\u001b[0m         layer_head_mask,\n\u001b[1;32m    613\u001b[0m         encoder_hidden_states,\n\u001b[1;32m    614\u001b[0m         encoder_attention_mask,\n\u001b[1;32m    615\u001b[0m         past_key_value,\n\u001b[1;32m    616\u001b[0m         output_attentions,\n\u001b[1;32m    617\u001b[0m     )\n\u001b[1;32m    619\u001b[0m hidden_states \u001b[39m=\u001b[39m layer_outputs[\u001b[39m0\u001b[39m]\n\u001b[1;32m    620\u001b[0m \u001b[39mif\u001b[39;00m use_cache:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/twitter-env/lib/python3.10/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/twitter-env/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py:537\u001b[0m, in \u001b[0;36mBertLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    534\u001b[0m     cross_attn_present_key_value \u001b[39m=\u001b[39m cross_attention_outputs[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\n\u001b[1;32m    535\u001b[0m     present_key_value \u001b[39m=\u001b[39m present_key_value \u001b[39m+\u001b[39m cross_attn_present_key_value\n\u001b[0;32m--> 537\u001b[0m layer_output \u001b[39m=\u001b[39m apply_chunking_to_forward(\n\u001b[1;32m    538\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfeed_forward_chunk, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mchunk_size_feed_forward, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mseq_len_dim, attention_output\n\u001b[1;32m    539\u001b[0m )\n\u001b[1;32m    540\u001b[0m outputs \u001b[39m=\u001b[39m (layer_output,) \u001b[39m+\u001b[39m outputs\n\u001b[1;32m    542\u001b[0m \u001b[39m# if decoder, return the attn key/values as the last output\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/twitter-env/lib/python3.10/site-packages/transformers/pytorch_utils.py:249\u001b[0m, in \u001b[0;36mapply_chunking_to_forward\u001b[0;34m(forward_fn, chunk_size, chunk_dim, *input_tensors)\u001b[0m\n\u001b[1;32m    246\u001b[0m     \u001b[39m# concatenate output at same dimension\u001b[39;00m\n\u001b[1;32m    247\u001b[0m     \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39mcat(output_chunks, dim\u001b[39m=\u001b[39mchunk_dim)\n\u001b[0;32m--> 249\u001b[0m \u001b[39mreturn\u001b[39;00m forward_fn(\u001b[39m*\u001b[39;49minput_tensors)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/twitter-env/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py:549\u001b[0m, in \u001b[0;36mBertLayer.feed_forward_chunk\u001b[0;34m(self, attention_output)\u001b[0m\n\u001b[1;32m    548\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfeed_forward_chunk\u001b[39m(\u001b[39mself\u001b[39m, attention_output):\n\u001b[0;32m--> 549\u001b[0m     intermediate_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mintermediate(attention_output)\n\u001b[1;32m    550\u001b[0m     layer_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput(intermediate_output, attention_output)\n\u001b[1;32m    551\u001b[0m     \u001b[39mreturn\u001b[39;00m layer_output\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/twitter-env/lib/python3.10/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/twitter-env/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py:450\u001b[0m, in \u001b[0;36mBertIntermediate.forward\u001b[0;34m(self, hidden_states)\u001b[0m\n\u001b[1;32m    448\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, hidden_states: torch\u001b[39m.\u001b[39mTensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m torch\u001b[39m.\u001b[39mTensor:\n\u001b[1;32m    449\u001b[0m     hidden_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdense(hidden_states)\n\u001b[0;32m--> 450\u001b[0m     hidden_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mintermediate_act_fn(hidden_states)\n\u001b[1;32m    451\u001b[0m     \u001b[39mreturn\u001b[39;00m hidden_states\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/twitter-env/lib/python3.10/site-packages/torch/nn/modules/module.py:1189\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1188\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_call_impl\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m-> 1189\u001b[0m     forward_call \u001b[39m=\u001b[39m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_slow_forward \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39;49m_C\u001b[39m.\u001b[39;49m_get_tracing_state() \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mforward)\n\u001b[1;32m   1190\u001b[0m     \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m     \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m             \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "sentiment_analysis(df_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "twitter-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
