{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import re\n",
    "import pickle\n",
    "import emoji\n",
    "import preprocessor\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('raw_data/tweets.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data.drop(columns=['media', 'inReplyToUser', 'mentionedUsers', 'lang', 'source', 'location'])\n",
    "df.rename(columns={'rawContent': 'tweet'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_datetime(df):\n",
    "    df['date'] = pd.to_datetime(df['date'], format='%Y-%m-%d %H:%M:%S')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_emojis(string):\n",
    "    text = emoji.demojize(string)\n",
    "    text = text.replace(\":\", \"\").replace(\"_\", \" \")\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_tweet(tweet):\n",
    "    \n",
    "    # Remove url\n",
    "    tweet = re.sub(r'https?:\\/\\/\\S+', '', tweet)\n",
    "    tweet = re.sub(r'http?:\\/\\/\\S+', '', tweet)\n",
    "    \n",
    "    # Remove \\n\n",
    "    tweet = re.sub(r'\\n', '', tweet)\n",
    "    \n",
    "    # Remove @\n",
    "    tweet = re.sub(r'@[A-Za-z0-9]+', '', tweet)\n",
    "    \n",
    "    # Remove #\n",
    "    tweet = re.sub(r'#', '', tweet)\n",
    "    \n",
    "    # Remove RT\n",
    "    tweet = re.sub(r'RT[\\s]+', '', tweet)\n",
    "    \n",
    "    # Convert to lower case\n",
    "    tweet = tweet.lower()\n",
    "    \n",
    "    # Remove \"#&'()*/:;@[\\]^`{|}~\"\n",
    "    tweet = re.sub(r'[#&\\'\\(\\)\\*\\+\\/:;@\\[\\]\\^`{|}~]', '', tweet)\n",
    "    \n",
    "    # Remove double space\n",
    "    tweet = re.sub(r'\\s\\s+', ' ', tweet)\n",
    "    \n",
    "    return tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_max_normalization(df):\n",
    "    df = df.copy()\n",
    "    \n",
    "    num_cols = df.select_dtypes(include=['float64', 'int64']).columns.tolist()\n",
    "    scaler = MinMaxScaler()\n",
    "    df[num_cols] = scaler.fit_transform(df[num_cols])\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = convert_to_datetime(df)\n",
    "df['tweet'] = df['tweet'].apply(clean_tweet)\n",
    "df['tweet'] = df['tweet'].apply(convert_emojis)\n",
    "df = min_max_normalization(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list1 = ['AAPL', 'Apple Inc.', 'Appl', 'AMC', 'AMC Entertainment Holdings Inc.', 'AAMC', 'AC', 'AMZN', 'Amazon.com Inc.', 'Amazn', 'AMD', 'Advanced Micro Devices Inc.', 'AMED', 'BB', 'BlackBerry Ltd.', 'Blacberry', 'BBBY', 'Bed Bath & Beyond Inc.', 'Bedbathbeyond', 'BTC', 'Bitcoin', 'bit coin', 'BYND', 'Beyond Meat Inc.', 'Bynd', 'CLNE', 'Clean Energy Fuels Corp.', 'Clnenergy', 'CMG', 'Chipotle Mexican Grill Inc.', 'Chipotle', 'COST', 'Costco Wholesale Corp.', 'Coscto', 'CRSR', 'Corsair Gaming Inc.', 'Corsair', 'DIS', 'Walt Disney Co.', 'Disney', 'DOGE', 'Dogecoin', 'Doge coin', 'ET', 'Energy Transfer LP', 'Energy Transfer', 'F', 'Ford Motor Co.', 'Ford', 'FB', 'Facebook Inc.', 'Fb', 'GME', 'GameStop Corp.', 'Gamestop', 'GOOG', 'Alphabet Inc.', 'Google', 'HD', 'Home Depot Inc.', 'Home Depo', 'INTC', 'Intel Corp.', 'Intell', 'JNJ', 'Johnson & Johnson', 'Johnsohn', 'KO', 'Coca-Cola Co.', 'Coca Cola', 'LULU', 'Lululemon Athletica Inc.', 'Lululemn', 'MCD', \"McDonald's Corp.\", \"McDonalds\", 'MGM', 'MGM Resorts International', 'Mgmresorts', 'MSFT', 'Microsoft Corp.', 'Micrsoft', 'MU', 'Micron Technology Inc.', 'Micron', 'NIO', 'NIO Inc.', 'Nio', 'NVDA', 'NVIDIA Corp.', 'Nivida', 'PFE', 'Pfizer Inc.', 'Pifzer', 'PINS', 'Pinterest Inc.', 'Pintrst', 'PLTR', 'Palantir Technologies Inc.', 'Palintir', 'QQQ', 'Invesco QQQ Trust', 'InvescoQQQ', 'RBLX', 'Roblox Corp.', 'Robloks', 'RIOT', 'Riot Blockchain Inc.', 'Riott', 'ROKU', 'Roku Inc.', 'Rokue', 'SNDL', 'Sundial Growers Inc.', 'Sundail', 'SPCE', 'Virgin Galactic Holdings Inc.', 'Spacex', 'SQ', 'Square Inc.', 'Squar', 'T', 'AT&T Inc.', 'Att', 'TSLA', 'Tesla Inc.', 'Teslla', 'TWTR', 'Twitter Inc.', 'Twiter', 'UBER', 'Uber Technologies Inc.', 'Ube', 'UPST', 'Upstart Holdings Inc.', 'Upstartholdings', 'V', 'Visa Inc.', 'Visa', 'WMT', 'Walmart Inc.', 'Walmrt', 'XOM', 'Exxon Mobil Corp.', 'Exxonmobil']\n",
    "list2 = ['AAL', 'American Airlines Group Inc.', 'Americanairlines',\n",
    "        'ABNB', 'Airbnb Inc.', 'AirBnB',\n",
    "        'ACB', 'Aurora Cannabis Inc.', 'Auroracannabis',\n",
    "        'AMRN', 'Amarin Corp. plc', 'Amerin',\n",
    "        'ARKK', 'ARK Innovation ETF', 'ARKinovation',\n",
    "        'BABA', 'Alibaba Group Holding Ltd.', 'Alibaba',\n",
    "        'BA', 'Boeing Co.', 'Boing',\n",
    "        'BAC', 'Bank of America Corp.', 'Bankofamerica',\n",
    "        'BIDU', 'Baidu Inc.', 'Bido',\n",
    "        'BILI', 'Bilibili Inc.', 'Billibili',\n",
    "        'BLNK', 'Blink Charging Co.', 'Blinkcharg',\n",
    "        'BMY', 'Bristol Myers Squibb Co.', 'Bristolmyers',\n",
    "        'BRK.A', 'Berkshire Hathaway Inc.', 'Berkshira',\n",
    "        'CCL', 'Carnival Corp.', 'Carnival',\n",
    "        'CGC', 'Canopy Growth Corp.', 'Canopygrowth',\n",
    "        'CHWY', 'Chewy Inc.', 'Chewycom',\n",
    "        'CSCO', 'Cisco Systems Inc.', 'Cicsco',\n",
    "        'CVS', 'CVS Health Corp.', 'Cvshealth',\n",
    "        'DAL', 'Delta Air Lines Inc.', 'Deltaairlines',\n",
    "        'DDOG', 'Datadog Inc.', 'DataDog',\n",
    "        'DISCA', 'Discovery Inc. - Class A', 'Discovera',\n",
    "        'DKNG', 'DraftKings Inc.', 'DraftKings',\n",
    "        'ENPH', 'Enphase Energy Inc.', 'Enphase',\n",
    "        'EQT', 'EQT Corp.', 'Eqtcorporation',\n",
    "        'FCEL', 'FuelCell Energy Inc.', 'Fuelcell',\n",
    "        'FSLY', 'Fastly Inc.', 'Fastly',\n",
    "        'GE', 'General Electric Co.', 'GeneralElectric',\n",
    "        'GM', 'General Motors Co.', 'GeneralMotors',\n",
    "        'GOLD', 'Barrick Gold Corp.', 'Goldmining',\n",
    "        'GPRO', 'GoPro Inc.', 'Gopro',\n",
    "        'GRWG', 'GrowGeneration Corp.', 'Growgen',\n",
    "        'HPE', 'Hewlett Packard Enterprise Co.', 'Hewlettpackard',\n",
    "        'IBB', 'iShares NASDAQ Biotechnology ETF', 'iSharesNasdaqBiotechnology',\n",
    "        'IBKR', 'Interactive Brokers Group Inc.', 'InterectiveBrokers',\n",
    "        'INO', 'Inovio Pharmaceuticals Inc.', 'Inovio',\n",
    "        'JD', 'JD.com Inc.', 'JD',\n",
    "        'JMIA', 'Jumia Technologies AG', 'Jumia',\n",
    "        'JPM', 'JPMorgan Chase & Co.', 'JPmorgan',\n",
    "        'KHC', 'Kraft Heinz Co.', 'KraftHeinz',\n",
    "        'LIT', 'Global X Lithium & Battery Tech ETF', 'GlobalXlithium',\n",
    "        'MARA', 'Marathon Digital Holdings Inc.', 'MarathonDigital',\n",
    "        'MRNA', 'Moderna Inc.', 'Modernna',\n",
    "        'NCLH', 'Norwegian Cruise Line Holdings Ltd.', 'Norwegiancruiseline',\n",
    "        'NET', 'Cloudflare Inc.', 'CloudFlare',\n",
    "        'NFLX', 'Netflix Inc.', 'Netlfix',\n",
    "        'NKE', 'Nike Inc.', 'Nike', 'NKLA', 'Nikola Corp.', 'Nicola', 'NOK', 'Nokia Corp.', 'Noka', 'O', 'Realty Income Corp.', 'Realtyincome', 'OGI', 'OrganiGram Holdings Inc.', 'Organigram', 'OTRK', 'Ontrak Inc.', 'OnTrack', 'PDD', 'Pinduoduo Inc.', 'Pinduoduo', 'PENN', 'Penn National Gaming Inc.', 'PennNational']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords = []\n",
    "\n",
    "for word in list1:\n",
    "    word = clean_tweet(word)\n",
    "    word = word.replace('inc.', '').replace('ltd.', '').replace('co.', '').replace('corp.', '').replace('.com', '')\n",
    "    keywords.append(word)\n",
    "\n",
    "for word in list2:\n",
    "    word = clean_tweet(word)\n",
    "    word = word.replace('inc.', '').replace('ltd.', '').replace('co.', '').replace('corp.', '').replace('.com', '')\n",
    "    keywords.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top50 = pd.read_csv('raw_data/top50.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cashtags = top50['cashtags'].tolist()\n",
    "hashtags = top50['hashtags'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cashtag in cashtags:\n",
    "    cashtag = clean_tweet(cashtag)\n",
    "    cashtag = re.sub(r'[^\\w\\s]', '', cashtag)\n",
    "    cashtag = cashtag.replace(' ', '')\n",
    "    \n",
    "    if cashtag not in keywords:\n",
    "        keywords.append(cashtag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for hashtag in hashtags:\n",
    "    hashtag = clean_tweet(hashtag)\n",
    "    hashtag = re.sub(r'[^\\w\\s]', '', hashtag)\n",
    "    hashtag = hashtag.replace(' ', '')\n",
    "    \n",
    "    if hashtag not in keywords:\n",
    "        keywords.append(hashtag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for keyword in keywords:\n",
    "    if len(keyword) < 2:\n",
    "        keywords.remove(keyword)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered = df[df['tweet'].str.contains(keyword).any() | df['cashtags'].notnull() | df['hashtags'].notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment_analysis(df):\n",
    "    \n",
    "    from transformers import BertTokenizer, BertForSequenceClassification, pipeline\n",
    "\n",
    "    finbert = BertForSequenceClassification.from_pretrained('yiyanghkust/finbert-tone',num_labels=3)\n",
    "    tokenizer = BertTokenizer.from_pretrained('yiyanghkust/finbert-tone')\n",
    "    nlp = pipeline(\"text-classification\", model=finbert, tokenizer=tokenizer)\n",
    "    \n",
    "    for i in range(len(df)):\n",
    "        results = nlp(df.iloc[i]['tweet'])\n",
    "        df['sentiment'] = results[0]['label']\n",
    "    \n",
    "    return df\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_analysis(df_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "twitter-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
